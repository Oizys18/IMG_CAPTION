# ğŸ¤ğŸ¥° ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê¸°ëŠ¥ êµ¬í˜„

![](https://img.shields.io/badge/version-2.0.0-green.svg) ![](https://img.shields.io/badge/created__at-20.04.03-yellow.svg) ![](https://img.shields.io/badge/updated__at-20.04.10-blue.svg)

> ì¸ê³µì§€ëŠ¥ í”„ë¡œì íŠ¸ "ì´ë¯¸ì§€ ìº¡ì…”ë‹ í™œìš© ì‹œìŠ¤í…œ" Sub PJT 2



## ğŸ›’ Table of Contents

- [Installation](#installation)
- [Quick Start](#Quick Start)
- [Features](#features)
- [Documentation](#Documentation)
- [Team](#Team)





## ğŸƒ Installation 

### Clone

- ë‹¤ìŒ ë§í¬ë¥¼ í†µí•´ ë¦¬í¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤.  
- HTTPS `https://lab.ssafy.com/s02-ai-sub2/s02p22a405.git`

### Setup

- ì´ë¯¸ì§€ íŒŒì¼ì„ [ë‹¤ìš´ë¡œë“œ](https://i02lab1.p.ssafy.io/) í•˜ê³  `datasets/` ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.

- ê°€ìƒí™˜ê²½ì„ ì„¤ì •í•´ì¤ë‹ˆë‹¤. í”„ë¡œì íŠ¸ëŠ” íŒ¨í‚¤ì§€ ê´€ë¦¬ ë° ê°€ìƒí™˜ê²½ ì„¤ì •ì„ ìœ„í•´ Anaconda ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

  ```bash
  conda env create -f AI.yaml
  ```

  - ë˜ëŠ” ë‹¤ìŒ [íŒŒì¼](.\doc\spec-file.txt)ì„ ì°¸ê³ í•˜ì—¬ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš© ëœ í”„ë¡œê·¸ë¨ì„ í™•ì¸, ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

  - ê¸°ë³¸ì ì¸ í”„ë¡œì íŠ¸ í™˜ê²½

    | ë¶„ë¥˜     | ê¸°ìˆ  ìŠ¤íƒ/ë„êµ¬ | ë²„ì „     |
    | -------- | -------------- | -------- |
    | ì–¸ì–´     | Python         | 3.7.6    |
    | ë¨¸ì‹ ëŸ¬ë‹ | Numpy          | 1.18.1   |
    |          | Scipy          | 1.4.1    |
    |          | Scikit-learn   | 0.22.1   |
    | ë”¥ëŸ¬ë‹   | Tensorflow     | 2.0.0    |
    |          | Keras          | 2.2.4-tf |
    | ì‹œê°í™”   | Matplotlib     | 3.1.3    |
    |          | Pillow         | 7.0.0    |
    | ê¸°íƒ€     | Anaconda       | 4.8.2    |

- ì»´í“¨í„°ì˜ í™˜ê²½ì— ë”°ë¼ config ë¥¼ í†µí•´ batch, epoch ì‚¬ì´ì¦ˆë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

- ë˜ëŠ” GPU í™˜ê²½ì„ ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ ì¡°ì •í•˜ë©´ ë” ì›í™œí•˜ê²Œ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ```python
  # train.py
  
  from tensorflow.compat.v1 import ConfigProto
  from tensorflow.compat.v1 import InteractiveSession
  
  config = ConfigProto()
  
  # ë°©ë²• 1
  config.gpu_options.per_process_gpu_memory_fraction = 0.4
  # ë°©ë²• 2
  config.gpu_options.allow_growth = True
  
  session = InteractiveSession(config=config)
  ```

  


## ğŸš€ Quick Start

- ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

  ```bash
  $python train.py
  ```

  - í¬í•¨í•œ `preprocess.py` ì˜ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - `train_datasets` & `test_datasets` ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì €ì¥í•˜ì—¬ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    - `tokernizer` ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. 
  - ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©° ì†ì‹¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤.


- í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ê²€ì¦í•˜ê³  í…ŒìŠ¤íŠ¸ í•©ë‹ˆë‹¤.

  ```bash
  $python predict.py
  ```

  - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì„ì˜ì˜ ì´ë¯¸ì§€ë¥¼ ë½‘ì•„ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
  - ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì„ ì‹œê°í™”í•˜ê³  ì‹¤ì œ ìº¡ì…˜ì„ í•¨ê»˜ ì¶œë ¥í•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.


- ì‚¬ìš©ìê°€ ì„ì˜ì˜ ì‚¬ì§„ì„ ì—…ë¡œë“œ í•˜ë©´ í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ìº¡ì…˜ì„ ìƒì„± í•©ë‹ˆë‹¤.

  ```bash
  $python demo.py
  ```

- ì´ë¯¸ì§€ ì¦ê°•ì´ ì–´ë–¤ ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§€ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.

  ```bash
  $python doc/img_augmentation_test.py
  ```

- ì •ê·œí™”í•œ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

  ```bash
  $python doc/image_normalization_test.py
  ```

  - ì´ë¯¸ì§€ë¥¼ ì–´ë–¤ ê°’ìœ¼ë¡œ ì •ê·œí™” í•  ê²ƒì¸ì§€ ê²°ì •í•˜ê¸° ìœ„í•´ ì´ ë‹¤ì„¯ê°€ì§€ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”í•œ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ë„ì›Œì¤ë‹ˆë‹¤. ì´ë¥¼ ê°ê° ë¹„êµí•˜ê³  ì–´ë– í•œ ê°’ì„ í™œìš©í•  ì§€ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    1. ì˜¤ë¦¬ì§€ë„ 
    2. ë„˜íŒŒì´ë¡œ min-max  ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    3. ë„˜íŒŒì´ë¡œ mean-std  ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    4. í…ì„œí”Œë¡œìš°ë¡œ mean-var ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    5. í…ì„œí”Œë¡œìš°ì—ì„œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ë°©ë²•

- í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬

  ```bash
  $python doc/tokenizer_sample.py
  ```

  - datasets/ ì•„ë˜ì— tokenizer_sample.pkl íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.
  - ì €ì¥ ëœ tokenizer ë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì–´ì§„ caption ì„ í† í°í™” í•˜ê³ , sample ë¡œ ë‘ ê°œ ì¶œë ¥í•©ë‹ˆë‹¤.





## âš¡ Features

### 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
â”œâ”€checkpoints
â”œâ”€data
â”‚  â”œâ”€ feature_extraction.py
â”‚  â”œâ”€ img_augmentation.py
â”‚  â””â”€ preprocess.py
â”œâ”€datasets
â”‚  â”œâ”€ images
â”‚  â”œâ”€ features
â”‚  â”œâ”€ captions.py
â”‚  â”œâ”€ config.csv
â”‚  â”œâ”€ tokernizer.pkl
â”‚  â”œâ”€ train_datasets.npy
â”‚  â””â”€ test_datasets.npy
â”œâ”€doc
â”‚  â”œâ”€images
â”‚  â”œâ”€meeting
â”‚  â”œâ”€ ì†”ì§€
â”‚  â”œâ”€ ìˆ˜ë¯¼
â”‚  â”œâ”€ ìˆ˜ì§„
â”‚  â”œâ”€ ì°¬ìš°
â”‚  â””â”€ í˜„ë™
â”œâ”€models
â”‚  â”œâ”€ decoder.py
â”‚  â””â”€ encoder.py
â”œâ”€utils
â”‚  â””â”€ utils.py
â”œâ”€ config.py
â”œâ”€ train.py
â””â”€ predict.py
```

- train.py, predict.py ë¥¼ ì‹¤í–‰ì‹œí‚¬ ë•Œ config ë¥¼ í†µí•´ batch, epoch ë“±ì˜ ë³€ìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì„¤ëª…ì€ ì•„ë˜ ì½”ë“œë¥¼ ì…ë ¥í•˜ì‹œë©´ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ ë³€ìˆ˜ë“¤ì€ íŒŒì¼ì„ ì‹¤í–‰ì‹œì¼°ì„ ë•Œ datastes/config.csv ì— ì €ì¥ë©ë‹ˆë‹¤.

```bash
$ python train.py -h
```





### 2. ë°ì´í„° ì „ì²˜ë¦¬

#### ë°ì´í„°ì…‹ ë¶„ë¦¬ ë° ì €ì¥

- `train.py` ì—ì„œ preprocess.pyì˜  `dataset_split_save ` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬`train_datasets` ê³¼ `test_datasets` íŒŒì¼ì˜ ìƒì„± ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì•„ì§ ë°ì´í„°ì…‹ì´ ì—†ë‹¤ë©´ ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬, ì €ì¥í•©ë‹ˆë‹¤.

  ``````python
  # preprocess.py
  
  def dataset_split_save(base_dir, caption_file_path, test_size):
      train_datasets_path = os.path.join(base_dir, 'train_datasets.npy')
      test_datasets_path = os.path.join(base_dir, 'test_datasets.npy')
      if not os.path.exists(train_datasets_path):
          dataset = get_path_caption(caption_file_path)
          train_dataset, val_dataset = train_test_split(dataset,
                                                        test_size=test_size,
                                                        shuffle=False)
          np.save(train_datasets_path, train_dataset)
          np.save(test_datasets_path, val_dataset)
          print('dataset ì„ train_datasets ê³¼ test_datasets ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.')
      else:
          print('ì €ì¥ ëœ train_datasets ê³¼ test_datasets ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.')
  ``````

- `test-size` ê°’ì„ config ë¡œ ì„¤ì •í•˜ì—¬ train-test ë¹„ìœ¨ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

#### ë°ì´í„° íŒŒì¼ ë¡œë“œ

- `config` ì„¤ì •ìœ¼ë¡œ train/test ì¤‘ ì–´ëŠ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¬ì§€ ì§€ì •í•©ë‹ˆë‹¤.

  ìƒ˜í”Œë§ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

- í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” `<start>` `<end>` í† í°ì„ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

#### í…ìŠ¤íŠ¸ í† í°í™”

- `tokenizer.pkl`ì´ ì—†ë‹¤ë©´ tokenizer ë¥¼ ìƒì„±, ì €ì¥í•©ë‹ˆë‹¤.

  ```python
  def get_tokenizer(tokenizer_path, caption_file_path, num_words):
      if not os.path.exists(tokenizer_path):
          dataset = get_path_caption(caption_file_path)
          captions = dataset[:, 2:]
  
          captions = np.squeeze(captions, axis=1)
          captions = ['<start>' + cap + ' <end>' for cap in captions]
  
          tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words + 1,
                                                            oov_token='<unk>',
                                                            lower=True,
                                                            split=' ',
                                                            filters='!"#$%&()*+.,-/:;=?@[\]^_`{|}~ ')
  
          tokenizer.fit_on_texts(captions)
          tokenizer.word_index['<pad>'] = 0
          tokenizer.index_word[0] = '<pad>'
  
          with open(tokenizer_path, 'wb') as f:
              pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)
      else:
          with open(tokenizer_path, 'rb') as f:
              tokenizer = pickle.load(f)
  
      return tokenizer
  ```

- ì €ì¥ ëœ Tokenizer ë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€ê²½, ê° ìº¡ì…˜ì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì¤ë‹ˆë‹¤.

  ```python
  def change_text_to_token(tokenizer_path, train_captions):
      with open(tokenizer_path, 'rb') as f:
          tokenizer = pickle.load(f)
      train_seqs = tokenizer.texts_to_sequences(train_captions)
      max_length = max(len(t) for t in train_seqs)
      cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')
      return cap_vector, max_length
  ```

#### ì´ë¯¸ì§€ ì •ê·œí™”

- ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ í•¨ê»˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.

  ``````python
  def load_image(image_path):
      img = tf.io.read_file(image_path)
      img = tf.image.decode_jpeg(img, channels=3)
      img = tf.image.resize(img, (299, 299))
      img = tf.keras.applications.inception_v3.preprocess_input(img)
      return img, image_path
  ``````

  InceptionV3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´, í•´ë‹¹ ëª¨ë¸ì— ì í•©í•œ í˜•íƒœë¡œ ì „ì²˜ë¦¬ í•˜ëŠ” ê³¼ì •ì„ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

#### ì´ë¯¸ì§€ ì¦ê°•

- íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ `imgaug`ë¥¼ ì‚¬ìš©í•˜ì—¬ Image Augmentation(ì´í•˜ ì´ë¯¸ì§€ ì¦ê°•) ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

  ```python
  from imgaug import augmenters as iaa
  # imgaug ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
  ```

  Sequentianl ì•ˆì—ì„œ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì´ë¯¸ì§€ ì¦ê°•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

  BlendAlpha ë¡œ ì•ŒíŒŒë¸”ë Œë”© ì‘ì—…ì„ ì¶”ê°€í•´ ì´ë¯¸ì§€ë¥¼ ì¦ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì´ë¯¸ì§€ ì¦ê°• ì‘ì—…ì€ `feature_extraction.py` ì—ì„œ í˜¸ì¶œí•©ë‹ˆë‹¤.

#### íŠ¹ì§• ì¶”ì¶œ

- `feature_extraction()` ì•ˆì—ì„œ ì´ë¯¸ì§€ ì¦ê°• ì‹¤í–‰ ì—¬ë¶€ë¥¼ íŒë³„í•˜ê³ , ìˆ˜í–‰í•©ë‹ˆë‹¤. ì¦ê°•ëœ ì´ë¯¸ì§€ëŠ” ë°ì´í„°ì…‹ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. ì¦ê°•í•œ ì´ë¯¸ì§€ë“¤ì—ì„œ íŠ¹ì§•ê°’ì„ ì¶”ì¶œí•  ë•ŒëŠ” ì‚¬ì „í•™ìŠµëœ InceptionV3 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. `preprocess` ì˜ `load_image` ë¶€ë¶„ì—ì„œ ì „ì²˜ë¦¬ ê³¼ì •ì„ ìˆ˜í–‰í•´ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´ë•Œ InceptionV3ì˜ í•™ìŠµì— ì£¼ë¡œ ì´ìš©ëœ í˜•ì‹ìœ¼ë¡œ ë§¤ì¹˜ì‹œí‚µë‹ˆë‹¤. `num_parallel_calls=tf.data.experimental.AUTOTUNE` ëŠ” ë³‘ë ¬ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , íŒŒì¼ì„ ì—¬ëŠ” ë° ê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.

- ì†ë„ìƒ(bottleneck)ì˜ ë¬¸ì œë¡œ ëª¨ë¸ë§ì€ ìµœì´ˆ 1ë²ˆë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

  ```python
  image_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet')
  new_input = image_model.input
  hidden_layer = image_model.layers[-1].output
  image_features_extract_model = tf.keras.Model(new_input, hidden_layer)
  ```



### 3. ì‹¤í–‰

#### ëª¨ë¸ í•™ìŠµ

-  RNN, CNN êµ¬í˜„ ì½”ë“œëŠ” í¬ê²ŒëŠ” TensorFlow ê³µì‹ ë¬¸ì„œ [Image captioning with visual attention](https://www.tensorflow.org/tutorials/text/image_captioning) ìë£Œë¥¼ ì°¸ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ìë£Œì—ì„œ Attention ê³¼ ê´€ë ¨í•œ ë¶€ë¶„ì€ [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044) ë¥¼ ì°¸ê³ í•©ë‹ˆë‹¤.



#### train_step

- `GradientTape` ëŠ” ìë™ ë¯¸ë¶„(ì£¼ì–´ì§„ ì…ë ¥ ë³€ìˆ˜ì— ëŒ€í•œ ì—°ì‚°ì˜ ê·¸ë˜ë””ì–¸íŠ¸gradient ë¥¼ ê³„ì‚°)í•˜ëŠ”  í…ì„œí”Œë¡œìš° API ì…ë‹ˆë‹¤. ([í…ì„œí”Œë¡œìš° ê³µì‹ë¬¸ì„œ](https://www.tensorflow.org/tutorials/customization/autodiff#ê·¸ë ˆë””ì–¸íŠ¸_í…Œì´í”„)) ê·¸ë ˆë””ì–¸íŠ¸ í…Œì´í”„ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

  ```python
  with tf.GradientTape() as tape:
  	...
  ```

#### checkpoint

- ì¼ì • ì§€ì ë§ˆë‹¤ ëª¨ë¸ ë³€ìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” checkpoint manager ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ê°€ ìˆë‹¤ë©´, ê°€ì¥ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ì˜ë¥¼ ë¶ˆëŸ¬ì™€ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.

![checkpoint](./doc/images/checkpoint.PNG)

#### Optimizer & Loss function

- optimizer ëŠ” `Adam` ì„, ì†ì‹¤ í•¨ìˆ˜ëŠ” integer ì¸ì½”ë”©ì´ë¯€ë¡œ `Sparse Categorical Cross Entropy` ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.



### 4. ê²°ê³¼ë¬¼

- `train.py` ì‹¤í–‰ì‹œ ì•„ë˜ì²˜ëŸ¼ ì¶œë ¥ë©ë‹ˆë‹¤.

![checkpoint_1](./doc/images/checkpoint_1.PNG)

- `predict.py` ì‹¤í–‰ì‹œ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  - ì¶œë ¥ ê²°ê³¼

    ![predict_1](./doc/images/predict_1.PNG)

- `demo.py` ì‹¤í–‰ ì‹œ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  - ì‚¬ì§„ ì„ íƒ

    ![demo_1](./doc/images/demo_1.PNG)

  - ì¶œë ¥ ê²°ê³¼

    ![demo_3](./doc/images/demo_3.PNG)



## ğŸ•µ Documentation

### í”„ë¡œì íŠ¸ ê´€ë¦¬

- [í”„ë¡œì íŠ¸ ê´€ë¦¬](./doc/dev_notice.md)



### ë©‹ì§„ğŸ’ª íŒ€ì›ë“¤ì´ ì •ë¦¬í•œ ë©‹ì§„ğŸ’ª ìë£Œë“¤

- ì†”ì§€, [ë°ì´í„° ì •ê·œí™”ì™€  CNN](./doc/ì†”ì§€/í”„ë¡œì íŠ¸ ê°œë… ì •ë¦¬.md)
- ì†”ì§€, [ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €, ì²´í¬í¬ì¸íŠ¸](./doc/ì†”ì§€/ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ê°œë… ì •ë¦¬.md)
- ì†”ì§€, [numpy ë°°ì—´ ë‹¤ë£¨ê¸°](./doc/ì†”ì§€/ì´ë¯¸ì§€ ì •ê·œí™”, ë°°ì—´.md)
- ìˆ˜ë¯¼, [í”„ë¡œì íŠ¸ ê¸°ë³¸ ê°œë…ê³¼ ì´ë¯¸ì§€ ìº¡ì…”ë‹ í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜](./doc/ìˆ˜ë¯¼/README.md)
- ìˆ˜ë¯¼, [ì›Œë“œ ì„ë² ë”©ê³¼ RNN, Attention](./doc/ìˆ˜ë¯¼/study_req5.md)
- ì°¬ìš°, [í¼ì…‰íŠ¸ë¡  Perceptron](./doc/ì°¬ìš°/í¼ì…‰íŠ¸ë¡  Perceptron.md)
- ì°¬ìš°, [ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ ê°œë…](./doc/ì°¬ìš°/ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ê°œë….md)
- ì°¬ìš°, [CNN](./doc/ì°¬ìš°/CNN.md)
- ìˆ˜ì§„, [ë°ì´í„° ì „ì²˜ë¦¬ - ì´ë¯¸ì§€ íŠ¹ì„± ì¶”ì¶œ](./doc/ìˆ˜ì§„/docs/ì´ë¯¸ì§€_íŠ¹ì§•_ì¶”ì¶œ(feature_extraction.md))
- ìˆ˜ì§„, [í•™ìŠµ ëª¨ë¸](./doc/ìˆ˜ì§„/docs/í•™ìŠµ(train).md)
- ìˆ˜ì§„, [Linear_Regression](./doc/ìˆ˜ì§„/docs/ì„ í˜•_íšŒê·€(Linear_Regression).md)
- í˜„ë™, [Tokenizer](./doc/í˜„ë™/Tokenizer.md)






## ğŸ’– Team

> SSAFY 2ê¸° 4ë°˜ 5íŒ€ : ê¹€ìˆ˜ë¯¼, ì–‘ì°¬ìš°, ì´ìˆ˜ì§„, ì¡°í˜„ë™, ìµœì†”ì§€ 

**	ë„ˆëŠ”**  ![team](./doc/images/team.jpg)



![ë”±ëŒ€íŒ€](./doc/images/team_ttakdae.png)



------

ì—¬ëŸ¬ë¶„ì´ ì‚¬ë‘í•˜ëŠ” ìì¡´ê°ì´ ë‚®ì€ ì¹œêµ¬ì—ê²Œ [ì´ ì˜ìƒ](https://youtu.be/d4XGFYNcUEc)ì„ ë³´ì—¬ì£¼ì„¸ìš”. ğŸ’•