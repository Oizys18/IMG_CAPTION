# ğŸ¤ğŸ¥° ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê¸°ëŠ¥ êµ¬í˜„

![](https://img.shields.io/badge/version-2.0.0-green.svg) ![](https://img.shields.io/badge/created__at-20.04.03-yellow.svg) ![](https://img.shields.io/badge/updated__at-20.04.10-blue.svg)

> ì¸ê³µì§€ëŠ¥ í”„ë¡œì íŠ¸ "ì´ë¯¸ì§€ ìº¡ì…”ë‹ í™œìš© ì‹œìŠ¤í…œ" Sub PJT 2



-----

## ğŸ›’ Table of Contents

- [Installation](#installation)
- [Quick Start](#Quick Start)
- [Features](#features)
- [Documentation](#Documentation)
- [Team](#Team)

---------





## ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸ Installation 

### Clone

- ë‹¤ìŒ ë§í¬ë¥¼ í†µí•´ ë¦¬í¬ë¥¼ í´ë¡ í•©ë‹ˆë‹¤.  
- HTTPS `https://lab.ssafy.com/s02-ai-sub2/s02p22a405.git`

### Setup

- ì´ë¯¸ì§€ íŒŒì¼ì„ [ë‹¤ìš´ë¡œë“œ](https://i02lab1.p.ssafy.io/) í•˜ê³  `datasets/` ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.

- ê°€ìƒí™˜ê²½ì„ ì„¤ì •í•´ì¤ë‹ˆë‹¤. í”„ë¡œì íŠ¸ëŠ” íŒ¨í‚¤ì§€ ê´€ë¦¬ ë° ê°€ìƒí™˜ê²½ ì„¤ì •ì„ ìœ„í•´ Anaconda ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

  ```bash
  conda env create -f AI.yaml
  ```

  - ë˜ëŠ” ë‹¤ìŒ [íŒŒì¼](.\doc\spec-file.txt)ì„ ì°¸ê³ í•˜ì—¬ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš© ëœ í”„ë¡œê·¸ë¨ì„ í™•ì¸, ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

  - ê¸°ë³¸ì ì¸ í”„ë¡œì íŠ¸ í™˜ê²½

    | ë¶„ë¥˜     | ê¸°ìˆ  ìŠ¤íƒ/ë„êµ¬ | ë²„ì „     |
    | -------- | -------------- | -------- |
    | ì–¸ì–´     | Python         | 3.7.6    |
    | ë¨¸ì‹ ëŸ¬ë‹ | Numpy          | 1.18.1   |
    |          | Scipy          | 1.4.1    |
    |          | Scikit-learn   | 0.22.1   |
    | ë”¥ëŸ¬ë‹   | Tensorflow     | 2.0.0    |
    |          | Keras          | 2.2.4-tf |
    | ì‹œê°í™”   | Matplotlib     | 3.1.3    |
    |          | Pillow         | 7.0.0    |
    | ê¸°íƒ€     | Anaconda       | 4.8.2    |





## ğŸš€ Quick Start

- ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

  ```bash
  $python train.py
  ```

  - í¬í•¨í•œ `preprocess.py` ì˜ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - `train_datasets` & `test_datasets` ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ì €ì¥í•˜ì—¬ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    - `tokernizer` ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. 
  - ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©° ì†ì‹¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

- í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ê²€ì¦í•˜ê³  í…ŒìŠ¤íŠ¸ í•©ë‹ˆë‹¤.

  ```bash
  $python predict.py
  ```

  - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì„ì˜ì˜ ì´ë¯¸ì§€ë¥¼ ë½‘ì•„ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
  - ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì„ ì‹œê°í™”í•˜ê³  ì‹¤ì œ ìº¡ì…˜ì„ í•¨ê»˜ ì¶œë ¥í•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

- ì •ê·œí™”í•œ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

  ```bash
  $python doc/image_normalization_test.py
  ```

  - ì´ë¯¸ì§€ë¥¼ ì–´ë–¤ ê°’ìœ¼ë¡œ ì •ê·œí™” í•  ê²ƒì¸ì§€ ê²°ì •í•˜ê¸° ìœ„í•´ ì´ ë‹¤ì„¯ê°€ì§€ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”í•œ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ë„ì›Œì¤ë‹ˆë‹¤. ì´ë¥¼ ê°ê° ë¹„êµí•˜ê³  ì–´ë– í•œ ê°’ì„ í™œìš©í•  ì§€ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    1. ì˜¤ë¦¬ì§€ë„ 
    2. ë„˜íŒŒì´ë¡œ min-max  ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    3. ë„˜íŒŒì´ë¡œ mean-std  ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    4. í…ì„œí”Œë¡œìš°ë¡œ mean-var ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    5. í…ì„œí”Œë¡œìš°ì—ì„œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ë°©ë²•

- í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬

  ```bash
  $python doc/tokenizer_sample.py
  ```

  - datasets/ ì•„ë˜ì— tokenizer_sample.pkl íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.
  - ì €ì¥ ëœ tokenizer ë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì–´ì§„ caption ì„ í† í°í™” í•˜ê³ , sample ë¡œ ë‘ ê°œ ì¶œë ¥í•©ë‹ˆë‹¤.





## âš¡ Features

### 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ product
|   â”œâ”€â”€ index.js
|   â”œâ”€â”€ product.js
|   â””â”€â”€ product.test.js
â”œâ”€â”€ user
|   â”œâ”€â”€ index.js
|   â”œâ”€â”€ user.js
|   â””â”€â”€ user.test.js
```



### 2. ë°ì´í„° ...ì „ì²˜ë¦¬........ê¾¸ì—ì—¥ã„±

#### ë°ì´í„°ì…‹ ë¶„ë¦¬ ë° ì €ì¥

- `train.py` ì—ì„œ `train_datasets_path` ì™€ `test_datasets_path` ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ, í•´ë‹¹ íŒŒì¼ì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ì•„ì§ ë°ì´í„°ì…‹ì´ ì—†ë‹¤ë©´ ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬, ì €ì¥í•˜ëŠ” `dataset_split_save()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

  ``````python
  # train.py
  
  train_datasets_path = os.path.join(BASE_DIR, 'train_datasets.npy')
  test_datasets_path = os.path.join(BASE_DIR, 'test_datasets.npy')
  if not os.path.exists(train_datasets_path):
      # ì´ë¯¸ì§€ ê²½ë¡œ ë° ìº¡ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
      dataset = preprocess.get_path_caption(config.caption_file_path)
      preprocess.dataset_split_save(dataset, BASE_DIR, config.test_size)
      print('dataset ì„ train_datasets ê³¼ test_datasets ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.')
  else:
      print('ì €ì¥ ëœ train_datasets ê³¼ test_datasets ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.')
  ``````

- `test-size` ê°’ì„ config ë¡œ ì„¤ì •í•˜ì—¬ train-test ë¹„ìœ¨ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

#### ë°ì´í„° íŒŒì¼ ë¡œë“œ

- `config` ì„¤ì •ìœ¼ë¡œ train/test ì¤‘ ì–´ëŠ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¬ì§€ ì§€ì •í•©ë‹ˆë‹¤.

  ìƒ˜í”Œë§ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

- í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” `<start>` `<end>` í† í°ì„ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

#### í…ìŠ¤íŠ¸ í† í°í™”



#### ì´ë¯¸ì§€ ì •ê·œí™”

- ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ í•¨ê»˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.

  ``````python
  def load_image(image_path):
      img = tf.io.read_file(image_path)
      img = tf.image.decode_jpeg(img, channels=3)
      img = tf.image.resize(img, (299, 299))
      img = tf.keras.applications.inception_v3.preprocess_input(img)
      return img, image_path
  ``````

  InceptionV3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´, í•´ë‹¹ ëª¨ë¸ì— ì í•©í•œ í˜•íƒœë¡œ ì „ì²˜ë¦¬ í•˜ëŠ” ê³¼ì •ì„ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

#### ì´ë¯¸ì§€ ì¦ê°•

``````python
from imgaug import augmenters as iaa
# imgaug ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
``````

íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ `imgaug` ì‚¬ìš©í•˜ì—¬ Image Augmentation(ì´í•˜ ì´ë¯¸ì§€ ì¦ê°•) ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

Sequentianl ì•ˆì—ì„œ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì´ë¯¸ì§€ ì¦ê°•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

BlendAlpha ë¡œ ì•ŒíŒŒë¸”ë Œë”© ì‘ì—…ì„ ì¶”ê°€í•´ ì´ë¯¸ì§€ë¥¼ ì¦ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì´ë¯¸ì§€ ì¦ê°• ì‘ì—…ì€ `feature_extraction.py` ì—ì„œ í˜¸ì¶œí•©ë‹ˆë‹¤.

  



### 3. ì‹¤..í–‰....



### 4. ê²°ê³¼ë¬¼













## ğŸ•µï¸â€â™€ï¸ğŸ•µï¸â€â™‚ï¸ Documentation

### í”„ë¡œì íŠ¸ ê´€ë¦¬

- [í”„ë¡œì íŠ¸ ê´€ë¦¬]()



### ë©‹ì§„ íŒ€ì›ë“¤ì´ ì •ë¦¬í•œ ë©‹ì§„ ìë£Œë“¤

- ì†”ì§€, [ë°ì´í„° ì •ê·œí™”ì™€  CNN, ì†ì‹¤í•¨ìˆ˜]()
- ì†”ì§€, [numpy ë°°ì—´ ë‹¤ë£¨ê¸°]()
- ìˆ˜ë¯¼, [í”„ë¡œì íŠ¸ ê¸°ë³¸ ê°œë…ê³¼ ì´ë¯¸ì§€ ìº¡ì…”ë‹ í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜]()
- ì°¬ìš°, [í¼ì…‰íŠ¸ë¡  Perceptron]()
- ì°¬ìš°, [ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ ê°œë…]()
- ì°¬ìš°, [CNN]()
- ìˆ˜ì§„, [ë°ì´í„° ì „ì²˜ë¦¬ - ì´ë¯¸ì§€ íŠ¹ì„± ì¶”ì¶œ]()
- ìˆ˜ì§„, [í•™ìŠµ ëª¨ë¸]()
- ìˆ˜ì§„, [Linear_Regression]()

- í˜„ë™, [Tokenizer]()






## ğŸ’– Team

> SSAFY 2ê¸° 4ë°˜ 5íŒ€ : ê¹€ìˆ˜ë¯¼, ì–‘ì°¬ìš°, ì´ìˆ˜ì§„, ì¡°í˜„ë™, ìµœì†”ì§€ 

**ë„ˆëŠ”**  ![team](C:\Users\multicampus\Desktop\Project\s02p22a405\doc\images\team.jpg)







------

ì—¬ëŸ¬ë¶„ì´ ì‚¬ë‘í•˜ëŠ” ìì¡´ê°ì´ ë‚®ì€ ì¹œêµ¬ì—ê²Œ [ì´ ì˜ìƒ](https://youtu.be/d4XGFYNcUEc)ì„ ë³´ì—¬ì£¼ì„¸ìš”. ğŸ’•